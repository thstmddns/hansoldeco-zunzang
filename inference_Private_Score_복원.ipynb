{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team 전장갓겜 Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OS: Ubuntu 20.04 LTS   \n",
    "Pytorch: 2.0.1  \n",
    "CUDA: 11.7  \n",
    "cuDNN: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas sentence_transformers transformers==4.37.1 tqdm pyarrow wandb spacy matplotlib\n",
    "!pip install bitsandbytes==0.41.1 accelerate==0.21.0 appdirs loralib black black[jupyter] datasets fire sentencepiece scipy numpy scikit-learn\n",
    "!pip install git+https://github.com/huggingface/peft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train_keyword_DB_JJGG.csv')\n",
    "\n",
    "def split_kw(keywords):\n",
    "    return keywords.split(' ')\n",
    "\n",
    "def split_df(df):\n",
    "    df['키워드list'] = df['키워드'].apply(lambda x: split_kw(x))\n",
    "    \n",
    "split_df(data)\n",
    "\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "new_rows = []  \n",
    "\n",
    "# 행 하나씩 순회\n",
    "for index, row in test_df.iterrows():\n",
    "    question = row['질문']\n",
    "    if not question.endswith(('.', '!', '?')):\n",
    "        question += '.'\n",
    "    \n",
    "    split_questions = re.findall('.+?[?!.]', question)\n",
    "    for q in split_questions:\n",
    "        new_rows.append({'id': row['id'], '질문': q})\n",
    "\n",
    "\n",
    "split_test_df = pd.DataFrame(new_rows)\n",
    "split_test_df['new_id'] = range(len(split_test_df))\n",
    "split_test_df = split_test_df[['id', 'new_id', '질문']]\n",
    "\n",
    "split_test_df.to_csv('./test_splited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./test_splited.csv\")\n",
    "\n",
    "def check_kw(question):\n",
    "    keyword_index = []\n",
    "    for i in range(len(data)):\n",
    "        k = 0 \n",
    "        for j in data[\"키워드list\"][i]:\n",
    "            if j in question:\n",
    "                k += 1\n",
    "        if k == len(data[\"키워드list\"][i]):\n",
    "            keyword_index.append(i)            \n",
    "    return keyword_index\n",
    "\n",
    "def index_kw(df):\n",
    "    df['keyword_match'] = df['질문'].apply(lambda x: check_kw(x))\n",
    "\n",
    "index_kw(test_df)\n",
    "\n",
    "def add_inst_1(df):\n",
    "    for i in range(len(df)):\n",
    "        # df[\"질문\"][i] = \"\\n### 질문:\" + df[\"질문\"][i]\n",
    "        for j in df[\"keyword_match\"][i]:\n",
    "            df[\"질문\"][i] = data[\"답변_3\"][j] + \" \" + df[\"질문\"][i]\n",
    "            \n",
    "add_inst_1(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_q = []\n",
    "for i in range(len(test_df)):\n",
    "    test_id = str(i).zfill(3)\n",
    "    if (test_df['id'].value_counts().get(f\"TEST_{test_id}\", 0)>1):\n",
    "        connected_q.append(i)\n",
    "        \n",
    "id_nums = []\n",
    "questions = []\n",
    "for j in connected_q:\n",
    "    test_id = str(j).zfill(3)\n",
    "    more_than_two = test_df[test_df[\"id\"]==f\"TEST_{test_id}\"]\n",
    "    if more_than_two[\"keyword_match\"].iloc[-1] == []:\n",
    "        for k in range(1, len(more_than_two)):\n",
    "            more_than_two[\"질문\"].iloc[0] += more_than_two[\"질문\"].iloc[k]\n",
    "            test_df[\"질문\"][more_than_two.index[0]] = more_than_two[\"질문\"].iloc[0]\n",
    "        for ind in range(1, len(more_than_two)):\n",
    "            test_df.drop(index=more_than_two.index[:][ind], axis=0, inplace=True)\n",
    "        questions.append(more_than_two[\"질문\"].iloc[0])\n",
    "        id_nums.append(j)\n",
    "        \n",
    "test_df.to_csv(\"drop_empty_keyword_splited_test_dab_3_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train_keyword_DB_JJGG.csv')\n",
    "split_df(data)\n",
    "\n",
    "test_df = pd.read_csv(\"./test_splited.csv\")\n",
    "index_kw(test_df)\n",
    "\n",
    "def add_inst_2(df):\n",
    "    for i in range(len(df)):\n",
    "        df[\"질문\"][i] = \"\\n### 질문:\" + df[\"질문\"][i]\n",
    "        for j in df[\"keyword_match\"][i]:\n",
    "            df[\"질문\"][i] = data[\"답변_3\"][j] + \" \" + df[\"질문\"][i]\n",
    "add_inst_2(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_q = []\n",
    "for i in range(len(test_df)):\n",
    "    test_id = str(i).zfill(3)\n",
    "    if (test_df['id'].value_counts().get(f\"TEST_{test_id}\", 0)>1):\n",
    "        connected_q.append(i)\n",
    "        \n",
    "id_nums = []\n",
    "questions = []\n",
    "for j in connected_q:\n",
    "    test_id = str(j).zfill(3)\n",
    "    more_than_two = test_df[test_df[\"id\"]==f\"TEST_{test_id}\"]\n",
    "    if more_than_two[\"keyword_match\"].iloc[-1] == []:\n",
    "        for k in range(1, len(more_than_two)):\n",
    "            more_than_two[\"질문\"].iloc[0] += more_than_two[\"질문\"].iloc[k]\n",
    "            test_df[\"질문\"][more_than_two.index[0]] = more_than_two[\"질문\"].iloc[0]\n",
    "        for ind in range(1, len(more_than_two)):\n",
    "            test_df.drop(index=more_than_two.index[:][ind], axis=0, inplace=True)\n",
    "        questions.append(more_than_two[\"질문\"].iloc[0])\n",
    "        id_nums.append(j)\n",
    "\n",
    "test_df.to_csv(\"drop_empty_keyword_splited_test_dab_3_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train_keyword_DB_JJGG.csv')\n",
    "split_df(data)\n",
    "\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "def split_sentences_with_delimiters_and_concat(text):\n",
    "\n",
    "    pattern = r'(까요[^\\.!\\?]|세요[^\\.!\\?]|건가요[^\\.!\\?]|한가요[^\\.!\\?]|나요[^\\.!\\?]|해줘[^\\.!\\?]|니까[^\\.\\?!])'\n",
    "    parts = re.split(pattern, text)\n",
    "\n",
    "    result = [part.strip() for part in parts if part.strip()]\n",
    "    if len(result) > 1:\n",
    "        result[0] += result[1]\n",
    "        result.pop(1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "for index, row in test_df.iterrows():\n",
    "    question = row['질문']\n",
    "    if not question.endswith(('.', '!', '?')):\n",
    "        question += '.'\n",
    "\n",
    "    split_questions = re.findall(r'(.+?까요[^.?!]|.+?세요[^.?!]|.+?가요[^.?!]|.+?나요[^.?!]|.+?해줘[^.?!]|.+?니까[^.?!]|.+?[?!.])', question)\n",
    "    for q in split_questions:\n",
    "        new_rows.append({'id': row['id'], '질문': q})\n",
    "\n",
    "\n",
    "split_test_df = pd.DataFrame(new_rows)\n",
    "split_test_df['new_id'] = range(len(split_test_df))\n",
    "split_test_df = split_test_df[['id', 'new_id', '질문']]\n",
    "\n",
    "split_test_df.to_csv('./test_splited_kkayo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./test_splited_kkayo.csv\")\n",
    "index_kw(test_df)\n",
    "\n",
    "connected_q = []\n",
    "for i in range(len(test_df)):\n",
    "    test_id = str(i).zfill(3)\n",
    "    if (test_df['id'].value_counts().get(f\"TEST_{test_id}\", 0)>1):\n",
    "        connected_q.append(i)\n",
    "        \n",
    "id_nums = []\n",
    "questions = []\n",
    "for j in connected_q:\n",
    "    test_id = str(j).zfill(3)\n",
    "    more_than_two = test_df[test_df[\"id\"]==f\"TEST_{test_id}\"]\n",
    "    if more_than_two[\"keyword_match\"].iloc[-1] == []:\n",
    "        more_than_two[\"질문\"].iloc[-2] += more_than_two[\"질문\"].iloc[-1]\n",
    "        test_df[\"질문\"][more_than_two.index[-2]] = more_than_two[\"질문\"].iloc[-2]\n",
    "        # for ind in range(1, len(more_than_two)):\n",
    "        test_df.drop(index=more_than_two.index[:][-1], axis=0, inplace=True)\n",
    "        questions.append(more_than_two[\"질문\"].iloc[0])\n",
    "        id_nums.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop=True)\n",
    "def add_inst_3(df):\n",
    "    for i in range(len(df)):\n",
    "        answer = []\n",
    "        keywords = []\n",
    "        for j in df[\"keyword_match\"][i]:\n",
    "            answer.append(data[\"답변_3\"][j])\n",
    "            for k in range(len(data[\"키워드list\"][j])):\n",
    "                if len(data[\"키워드list\"][j][k])>1:\n",
    "                    keywords.append(data[\"키워드list\"][j][k])\n",
    "            # df[\"질문\"][i] = data[\"답변_3\"][j] + \" \" + df[\"질문\"][i]\n",
    "        answer = set(answer)\n",
    "        answer = list(answer)\n",
    "        keywords = set(keywords)\n",
    "        keywords = list(keywords)\n",
    "        if len(df[\"keyword_match\"][i])==0:\n",
    "            df[\"질문\"][i] = \" \".join(answer) + \" ###질문:\" + df[\"질문\"][i]\n",
    "        else:\n",
    "            df[\"질문\"][i] = \" \".join(answer) + \" \" + df[\"질문\"][i] + \"\\n###질문: \" + df[\"질문\"][i] + \"\\n###질문: \" + df[\"질문\"][i]\n",
    "add_inst_3(test_df)\n",
    "\n",
    "test_df.to_csv(\"./kkayo_nokey_24_03_10_drop_empty_keyword_splited_test_dab_3-add-three-sharp-q.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'auto' \n",
    "\n",
    "########################################\n",
    "# base_LLM_model = './custom_LLM_llama_weight' # 구글 드라이브를 통해 모델을 직접 다운받은 경우\n",
    "base_LLM_model = 'Chaeseung/exp021' # 전장갓겜 허깅페이스 레포지토리에 저장된 모델을 쓰는 경우\n",
    "########################################\n",
    "\n",
    "test_df = pd.read_csv('drop_empty_keyword_splited_test_dab_3_1.csv')\n",
    "\n",
    "pipe = pipeline('text-generation', model=base_LLM_model, device_map='auto')\n",
    "\n",
    "def generate_pipeline(text):\n",
    "\n",
    "    output = pipe(f'''\n",
    "    당신은 실내 인테리어 전문 회사에 다니고 있는 친절한 전문가야. 서론을 제외하고 대답해줘.\n",
    "    ### 질문: {text} \n",
    "    \n",
    "    ### 응답:''', max_new_tokens=450, eos_token_id=2, return_full_text=False)\n",
    "    return output[0][\"generated_text\"]\n",
    "\n",
    "test_df['답변'] = test_df['질문'].progress_apply(generate_pipeline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_cut(sentence):\n",
    "    split_questions_use_findall = re.findall('.+?[?!.]', sentence)\n",
    "    if split_questions_use_findall[-1][-1] not in ['.', '!', '?', '다', '요']:\n",
    "        split_questions_use_findall = split_questions_use_findall[:-1]\n",
    "    return \"\".join(split_questions_use_findall)\n",
    "\n",
    "test_df[\"답변\"] = test_df[\"답변\"].progress_apply(lambda x: sentence_cut(x))\n",
    "\n",
    "connected_a = []\n",
    "for i in range(len(test_df)):\n",
    "    test_id = str(i).zfill(3)\n",
    "    if (test_df['id'].value_counts().get(f\"TEST_{test_id}\", 0)>1):\n",
    "        connected_a.append(i)\n",
    "\n",
    "id_nums = []\n",
    "answers = []\n",
    "for j in connected_a:\n",
    "    test_id = str(j).zfill(3)\n",
    "    more_than_two = test_df[test_df[\"id\"]==f\"TEST_{test_id}\"]\n",
    "    for k in range(1, len(more_than_two)):\n",
    "        more_than_two[\"답변\"].iloc[0] += more_than_two[\"답변\"].iloc[k]\n",
    "        test_df[\"답변\"][more_than_two.index[0]] = more_than_two[\"답변\"].iloc[0]\n",
    "    for ind in range(1, len(more_than_two)):\n",
    "        test_df.drop(index=more_than_two.index[:][ind], axis=0, inplace=True)\n",
    "    answers.append(more_than_two[\"답변\"].iloc[0])\n",
    "    id_nums.append(j)\n",
    "    \n",
    "preds = test_df['답변'].tolist()\n",
    "model2 = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "pred_embeddings = model2.encode(preds)\n",
    "\n",
    "submit = pd.read_csv(\"sample_submission.csv\")\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "llama_sub = submit\n",
    "llama_sub_drop = llama_sub.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    ########################################\n",
    "    # base_model='./custom_LLM_agiin_weight' # 구글 드라이브를 통해 모델을 직접 다운받은 경우\n",
    "    base_model='Chaeseung/dobae_agiin' # 전장갓겜 허깅페이스 레포지토리에 저장된 모델을 쓰는 경우\n",
    "    ########################################\n",
    "    preprocessed_test_df = 'drop_empty_keyword_splited_test_dab_3_2.csv'\n",
    "    max_new_tokens=450\n",
    "    sentence_num = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'auto' \n",
    "base_LLM_model = CFG.base_model\n",
    "test_df = pd.read_csv(CFG.preprocessed_test_df)\n",
    "\n",
    "pipe = pipeline('text-generation', model=base_LLM_model, device_map='auto')\n",
    "\n",
    "def generate_pipeline(text):\n",
    "\n",
    "    output = pipe(f'''\n",
    "    ### 지침: 당신은 실내 인테리어 전문 회사에 다니고 있는 친절한 전문가야. 질문에 대답할 때는 질문에 관련된 내용에 대해서만 답변을 해줘. 답변은 최소 두 문장 이상을 해야해.\n",
    "    ### 참고할 내용: {text} \n",
    "\n",
    "    ### 답변:''', max_new_tokens=CFG.max_new_tokens, eos_token_id=2, pad_token_id=0, return_full_text=False)\n",
    "    return output[0][\"generated_text\"]\n",
    "\n",
    "test_df['답변'] = test_df['질문'].progress_apply(generate_pipeline) \n",
    "test_df[\"답변\"] = test_df[\"답변\"].progress_apply(lambda x: sentence_cut(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_a = []\n",
    "for i in range(len(test_df)):\n",
    "    test_id = str(i).zfill(3)\n",
    "    if (test_df['id'].value_counts().get(f\"TEST_{test_id}\", 0)>1):\n",
    "        connected_a.append(i)\n",
    "        \n",
    "id_nums = []\n",
    "answers = []\n",
    "for j in connected_a:\n",
    "    test_id = str(j).zfill(3)\n",
    "    more_than_two = test_df[test_df[\"id\"]==f\"TEST_{test_id}\"]\n",
    "    for k in range(1, len(more_than_two)):\n",
    "        more_than_two[\"답변\"].iloc[0] += more_than_two[\"답변\"].iloc[k]\n",
    "        test_df[\"답변\"][more_than_two.index[0]] = more_than_two[\"답변\"].iloc[0]\n",
    "    for ind in range(1, len(more_than_two)):\n",
    "        test_df.drop(index=more_than_two.index[:][ind], axis=0, inplace=True)\n",
    "    answers.append(more_than_two[\"답변\"].iloc[0])\n",
    "    id_nums.append(j)\n",
    "    \n",
    "preds = test_df['답변'].tolist()\n",
    "model2 = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "pred_embeddings = model2.encode(preds)\n",
    "\n",
    "submit = pd.read_csv(\"sample_submission.csv\")\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "agiin_sub_1 = submit\n",
    "agiin_sub_1_drop = agiin_sub_1.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG_2:\n",
    "    ########################################\n",
    "    # base_model='./custom_LLM_agiin_weight' # 구글 드라이브를 통해 모델을 직접 다운받은 경우\n",
    "    base_model='Chaeseung/dobae_agiin' # 전장갓겜 허깅페이스 레포지토리에 저장된 모델을 쓰는 경우 \n",
    "    ########################################\n",
    "    preprocessed_test_df = 'kkayo_nokey_24_03_10_drop_empty_keyword_splited_test_dab_3-add-three-sharp-q.csv'\n",
    "    max_new_tokens=450\n",
    "    sentence_num = 4\n",
    "    qna_csv = 'TEST_Output_QnA.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'auto' \n",
    "base_LLM_model = CFG_2.base_model\n",
    "test_df = pd.read_csv(CFG_2.preprocessed_test_df)\n",
    "\n",
    "pipe = pipeline('text-generation', model=base_LLM_model, device_map=\"auto\")\n",
    "def generate_pipeline(text):\n",
    "\n",
    "    output = pipe(f'''\n",
    "    ### 지침: 당신은 실내 인테리어 전문 회사에 다니고 있는 친절한 전문가야. 다음 내용에서 질문에 관련한 내용만 답변을 해줘. 답변은 최소 두 문장 이상을 해야해.\n",
    "    ### 참고할 내용과 질문: {text} \n",
    "    \n",
    "    ### 답변:''', max_new_tokens=CFG_2.max_new_tokens, eos_token_id=2, pad_token_id=0, return_full_text=False)\n",
    "    return output[0][\"generated_text\"]\n",
    "\n",
    "test_df['답변'] = test_df['질문'].progress_apply(generate_pipeline) \n",
    "test_df[\"답변\"] = test_df[\"답변\"].progress_apply(lambda x: sentence_cut(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_a = []\n",
    "for i in range(len(test_df)):\n",
    "    test_id = str(i).zfill(3)\n",
    "    if (test_df['id'].value_counts().get(f\"TEST_{test_id}\", 0)>1):\n",
    "        connected_a.append(i)\n",
    "        \n",
    "id_nums = []\n",
    "answers = []\n",
    "for j in connected_a:\n",
    "    test_id = str(j).zfill(3)\n",
    "    more_than_two = test_df[test_df[\"id\"]==f\"TEST_{test_id}\"]\n",
    "    for k in range(1, len(more_than_two)):\n",
    "        more_than_two[\"답변\"].iloc[0] += more_than_two[\"답변\"].iloc[k]\n",
    "        test_df[\"답변\"][more_than_two.index[0]] = more_than_two[\"답변\"].iloc[0]\n",
    "    for ind in range(1, len(more_than_two)):\n",
    "        test_df.drop(index=more_than_two.index[:][ind], axis=0, inplace=True)\n",
    "    answers.append(more_than_two[\"답변\"].iloc[0])\n",
    "    id_nums.append(j)\n",
    "    \n",
    "preds = test_df['답변'].tolist()\n",
    "test_df.to_csv(CFG_2.qna_csv)\n",
    "model2 = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "pred_embeddings = model2.encode(preds)\n",
    "\n",
    "submit = pd.read_csv(\"sample_submission.csv\")\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "agiin_sub_2 = submit\n",
    "agiin_sub_2_drop = agiin_sub_2.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub = (0.3*llama_sub_drop + 0.5*agiin_sub_1_drop + 0.2*agiin_sub_2_drop)\n",
    "final_embeddings = pd.concat([agiin_sub_2[\"id\"], final_sub], axis=1)\n",
    "final_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embeddings.to_csv(\"final_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newtorch_kernel",
   "language": "python",
   "name": "newtorch"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
